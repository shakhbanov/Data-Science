{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import f1_score\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords as nltk_stopwords, wordnet\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# снимаем ограничение на количество столбцов\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# снимаем ограничение на ширину столбцов\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# игнорируем предупреждения\n",
    "pd.set_option('chained_assignment', None)  \n",
    "\n",
    "# выставляем ограничение на показ знаков после запятой\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Установка ядра tqdm_notebook для отображения прогресса в цикле\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv', index_col='Unnamed: 0')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                             text  \\\n",
       "159446  \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"   \n",
       "159447                                                                                                                                                                                                      You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93   \n",
       "159448                                                                                                                                                                                                                        Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159449                                                                                                                                                                                       And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.   \n",
       "159450                                                                                                             \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"   \n",
       "\n",
       "        toxic  \n",
       "159446      0  \n",
       "159447      0  \n",
       "159448      0  \n",
       "159449      0  \n",
       "159450      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head(), data.tail(), data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159,292.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           toxic\n",
       "count 159,292.00\n",
       "mean        0.10\n",
       "std         0.30\n",
       "min         0.00\n",
       "25%         0.00\n",
       "50%         0.00\n",
       "75%         0.00\n",
       "max         1.00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid black 2px; padding: 10px\">  \n",
    "    \n",
    "**Комментарий:**  \n",
    "    \n",
    "Здесь мы наблюдаем значительный дисбаланс классов в целевой переменной. Это в свою очередь может привести к несбалансированности и к переобучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация объекта класса TextProcessor\n",
    "# с параметром языка стоп-слов по умолчанию 'english'\n",
    "class TextProcessor:\n",
    "    \"\"\"\n",
    "    Класс для обработки текста, включая очистку от лишних символов, удаление стоп-слов и лемматизацию.\n",
    "\n",
    "    Атрибуты:\n",
    "        stopwords (set): Множество стоп-слов для указанного языка.\n",
    "        lemmatizer (WordNetLemmatizer): Объект для лемматизации слов с использованием WordNetLemmatizer.\n",
    "\n",
    "    Методы:\n",
    "        clear_text(text): Очищает текст от лишних символов и стоп-слов.\n",
    "        lemm_text(text): Лемматизирует текст.\n",
    "        postag_lemm_text(text): Лемматизирует текст с учетом частей речи.\n",
    "        get_wordnet_pos(word): Возвращает POS-тег WordNet для слова.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, stopwords_language='english'):\n",
    "        # Загрузка стоп-слов для указанного языка\n",
    "        self.stopwords = set(nltk_stopwords.words(stopwords_language))\n",
    "        # Инициализация объекта для лемматизации слов с помощью WordNetLemmatizer\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "    # Метод для очистки текста от лишних символов и стоп-слов\n",
    "    def clear_text(self, text):\n",
    "        # Приведение текста к нижнему регистру\n",
    "        text = text.lower()\n",
    "        # Оставление только латинских символов\n",
    "        word_list = re.sub(r\"[^a-z ]\", ' ', text).split()\n",
    "        # Разделение текста на отдельные слова и удаление нелатинских символов\n",
    "        # Фильтрация списка слов и удаление стоп-слов\n",
    "        word_notstop_list = [w for w in word_list if w not in self.stopwords]\n",
    "        # Сборка очищенных слов в текстовую строку и возврат результата\n",
    "        return ' '.join(word_notstop_list)\n",
    "    \n",
    "    # Метод для лемматизации текста\n",
    "    def lemm_text(self, text):\n",
    "        # Разделение текста на отдельные слова\n",
    "        word_list = text.split()\n",
    "        # Лемматизация каждого слова в тексте с использованием WordNetLemmatizer\n",
    "        lemmatized_text = ' '.join([self.lemmatizer.lemmatize(w) for w in word_list])\n",
    "        # Сборка лемматизированных слов в текстовую строку и возврат результата\n",
    "        return lemmatized_text\n",
    "    \n",
    "    # Метод для лемматизации текста с учетом частей речи\n",
    "    def postag_lemm_text(self, text):\n",
    "        # Разделение текста на отдельные слова\n",
    "        word_list = text.split()\n",
    "        # Лемматизация каждого слова в тексте с использованием WordNetLemmatizer и определением части речи\n",
    "        lemmatized_text = ' '.join([self.lemmatizer.lemmatize(w, self.get_wordnet_pos(w)) for w in word_list])\n",
    "        # Сборка лемматизированных слов в текстовую строку и возврат результата\n",
    "        return lemmatized_text\n",
    "    \n",
    "    @staticmethod\n",
    "    # Статический метод для определения части речи слова с использованием pos_tag\n",
    "    def get_wordnet_pos(word):\n",
    "        # Получение POS-тега для слова с использованием pos_tag\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        # Отображение POS-тегов WordNet на первую букву, используемую lemmatize\n",
    "        tag_dict = {\"J\": 'a', \"N\": 'n', \"V\": 'v', \"R\": 'r'}\n",
    "        # Возврат соответствующего POS-тега WordNet или 'n' (существительное) по умолчанию\n",
    "        return tag_dict.get(tag, 'n')\n",
    "\n",
    "# Инициализация объекта для обработки текста\n",
    "text_processor = TextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ee3dc5dd19425daf66fd43b877a589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eeb47623e11465e9f18e03bb9d05309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5454f42280824930b55d468f29f7611a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Очистка текста\n",
    "data['clean_text'] = data['text'].progress_apply(text_processor.clear_text)\n",
    "\n",
    "# Лемматизация текста\n",
    "data['wnl_text'] = data['clean_text'].progress_apply(text_processor.lemm_text)\n",
    "\n",
    "# Лемматизация с POS-тегами\n",
    "data['wnlpostag_text'] = data['clean_text'].progress_apply(text_processor.postag_lemm_text)\n",
    "\n",
    "# Классификаторы и настройки\n",
    "classifiers = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(solver='liblinear', class_weight='balanced', random_state=12345),\n",
    "        'data': 'wnl_text'\n",
    "    },\n",
    "    'RandomForestClassifier': {\n",
    "        'model': RandomForestClassifier(n_estimators=10, class_weight='balanced', random_state=12345),\n",
    "        'data': 'wnl_text'\n",
    "    },\n",
    "    'LogisticRegression_POS': {\n",
    "        'model': LogisticRegression(solver='liblinear', class_weight='balanced', random_state=12345),\n",
    "        'data': 'wnlpostag_text'\n",
    "    },\n",
    "    'RandomForestClassifier_POS': {\n",
    "        'model': RandomForestClassifier(n_estimators=10, class_weight='balanced', random_state=12345),\n",
    "        'data': 'wnlpostag_text'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Создание DataFrame для результатов\n",
    "results = pd.DataFrame(columns=['Model', 'Data', 'F1-Score', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame для результатов\n",
    "results = pd.DataFrame(columns=['Model', 'Data', 'F1-Score', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Models:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Кросс-валидация с использованием моделей\n",
    "kfold = KFold(n_splits=5, random_state=12345, shuffle=True)\n",
    "\n",
    "# Создайте функцию для обучения и оценки модели\n",
    "def train_model(model, tf_idf_train, target_train):\n",
    "    # Обучение модели\n",
    "    model.fit(tf_idf_train, target_train)\n",
    "    # Расчет F1-оценки\n",
    "    f1_scores = cross_val_score(model, tf_idf_train, target_train, cv=kfold, scoring='f1')\n",
    "    return f1_scores.mean()\n",
    "\n",
    "for model_name, model_params in tqdm_notebook(classifiers.items(), desc='Models', leave=False):\n",
    "    model = model_params['model']\n",
    "    model_data = model_params['data']\n",
    "    \n",
    "    # Разделение на тренировочный и тестовый наборы\n",
    "    features_train, features_test, target_train, target_test = train_test_split(\n",
    "        data[model_data], data['toxic'].values, test_size=0.2, stratify=data['toxic'].values, \n",
    "        shuffle=True, random_state=12345\n",
    "    )\n",
    "    \n",
    "    # Преобразование текста в TF-IDF векторы\n",
    "    count_tf_idf = TfidfVectorizer()\n",
    "    tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "    tf_idf_test = count_tf_idf.transform(features_test)\n",
    "    \n",
    "    # Обучение модели и расчет F1-оценки с использованием параллельной обработки\n",
    "    beg_time = datetime.datetime.now()\n",
    "    f1_scores = Parallel(n_jobs=-1)(\n",
    "        delayed(train_model)(model, tf_idf_train, target_train) for _ in range(5)\n",
    "    )\n",
    "    time_taken = (datetime.datetime.now() - beg_time).seconds\n",
    "    \n",
    "    # Предсказание на тестовом наборе данных\n",
    "    predictions = model.predict(tf_idf_test)\n",
    "    \n",
    "    # Расчет F1-оценки\n",
    "    f1_score_value = f1_score(target_test, predictions)\n",
    "    \n",
    "    # Запись результатов в DataFrame\n",
    "    results = results.append({\n",
    "        'Model': model_name,\n",
    "        'Data': model_data,\n",
    "        'F1-Score': f1_score_value,\n",
    "        'Time': time_taken\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.76</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression_POS</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.76</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier_POS</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model            Data  F1-Score  Time\n",
       "0          LogisticRegression        wnl_text      0.76   349\n",
       "1      RandomForestClassifier        wnl_text      0.60  2488\n",
       "2      LogisticRegression_POS  wnlpostag_text      0.76   377\n",
       "3  RandomForestClassifier_POS  wnlpostag_text      0.59  2256"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-оценка для лучшей модели (LogisticRegression): 0.760\n"
     ]
    }
   ],
   "source": [
    "# Выбор лучшей модели (логистической регрессии) из результатов\n",
    "best_model_name = results.loc[results['F1-Score'].idxmax(), 'Model']\n",
    "best_model_data = classifiers[best_model_name]['data']\n",
    "best_model = classifiers[best_model_name]['model']\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы для лучшей модели\n",
    "features_train_best, features_test_best, target_train_best, target_test_best = train_test_split(\n",
    "    data[best_model_data], data['toxic'].values, test_size=0.2, stratify=data['toxic'].values,\n",
    "    shuffle=True, random_state=12345\n",
    ")\n",
    "\n",
    "# Преобразование текста в TF-IDF векторы для лучшей модели\n",
    "count_tf_idf_best = TfidfVectorizer()\n",
    "tf_idf_train_best = count_tf_idf_best.fit_transform(features_train_best)\n",
    "tf_idf_test_best = count_tf_idf_best.transform(features_test_best)\n",
    "\n",
    "# Обучение лучшей модели\n",
    "best_model.fit(tf_idf_train_best, target_train_best)\n",
    "\n",
    "# Предсказание на тестовом наборе данных\n",
    "predictions_best = best_model.predict(tf_idf_test_best)\n",
    "\n",
    "# Вычисление метрики F1-Score для лучшей модели\n",
    "f1_score_best = f1_score(target_test_best, predictions_best)\n",
    "\n",
    "# Вывод результата\n",
    "print('F1-оценка для лучшей модели (%s): %.3f' % (best_model_name, f1_score_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не было обнаружено пропусков или дубликатов в данных, и все требуемые модели были успешно обучены.  \n",
    "Модель `Logistic Regression` показала лучший результат с точки зрения метрики **F1** исследования на тестовой выборке, ее оценка составляет `0.76`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Туториалы по Pipeline:⚠️:</b> \n",
    "\n",
    "* https://towardsdatascience.com/nlp-with-pipeline-gridsearch-5922266e82f4\n",
    "* https://scikit-learn.org/1.0/auto_examples/model_selection/grid_search_text_feature_extraction.html\n",
    "* https://habr.com/ru/articles/266025/\n",
    "* https://medium.datadriveninvestor.com/improve-the-text-classification-results-with-a-suitable-preprocessing-step-gridsearchcv-and-f19cb3e182a3\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "<font color='blue'>Полезные материалы:</font>\n",
    "    <ul><li>Про BERT:</li>\n",
    "    <ul>\n",
    "        <li>Яндекс Практикум, RuBERT</li>\n",
    "        <li>https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894 - Полный туториал-обучение по BERT</li>\n",
    "        <li>https://medium.com/analytics-vidhya/text-classification-with-bert-using-transformers-for-long-text-inputs-f54833994dfd - Тоже туториал про классификации, но для длинных текстов</li>\n",
    "        <li>https://huggingface.co/docs/transformers/tasks/sequence_classification - Официальный пример из документации huggingface</li>\n",
    "        <li>https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb - <b>Отличный туториал по реальному соревнованию</b></li>\n",
    "    </ul>\n",
    "    <li>Про GPU:</li>\n",
    "    <ul>\n",
    "        <li>https://colab.research.google.com/ - Google Colab для эффективного обучения</li>\n",
    "        <li>https://www.tutorialspoint.com/google_colab/google_colab_using_free_gpu.htm - Как включить GPU в Google Colab</li>\n",
    "        <li>https://huggingface.co/docs/transformers/performance - Как BERT обучать на GPU</li>\n",
    "    </ul>\n",
    "            <li>Про catboost:</li>\n",
    "    <ul>\n",
    "        <li>https://towardsdatascience.com/10x-times-fast-catboost-training-speed-with-an-nvidia-gpu-5ffefd9b57a6 - Сравнение GPU и CPU + код обучения на GPU</li>\n",
    "        <li>https://colab.research.google.com/github/catboost/tutorials/blob/master/tools/google_colaboratory_cpu_vs_gpu_tutorial.ipynb - Тетрадка туториал по GPU и CPU catboost</li>\n",
    "    </ul>\n",
    "        <li>Про Pipelines:</li>\n",
    "    <ul>\n",
    "        <li>https://habr.com/ru/post/266025/</li>\n",
    "        <li>https://towardsdatascience.com/nlp-with-pipeline-gridsearch-5922266e82f4</li>\n",
    "        <li>https://scikit-learn.org/0.24/auto_examples/model_selection/grid_search_text_feature_extraction.html</li>\n",
    "        <li>https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "    \n",
    "Сейчас активно используются RNN (LSTM) и трансформеры (BERT, ELMO, GPT/2/3/n и др.). Они не являются панацеей, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут решать задачи в текстах. \\\n",
    "BERT тяжелый, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.Также не всегда есть возможность обучиться на всём датасете из-за нехватки памяти, поэтому стоит брать **выборки** из датасета\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множество реализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)</font>"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1543,
    "start_time": "2023-06-11T08:27:48.424Z"
   },
   {
    "duration": 663,
    "start_time": "2023-06-11T08:29:55.432Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T08:30:28.847Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T08:30:30.174Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T08:30:37.883Z"
   },
   {
    "duration": 3152,
    "start_time": "2023-06-11T08:31:50.695Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-11T08:31:57.798Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-11T08:32:30.158Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-11T08:32:44.288Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-11T08:32:56.596Z"
   },
   {
    "duration": 24,
    "start_time": "2023-06-11T08:33:14.621Z"
   },
   {
    "duration": 206,
    "start_time": "2023-06-11T08:33:23.697Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T08:33:33.520Z"
   },
   {
    "duration": 120,
    "start_time": "2023-06-11T08:36:48.614Z"
   },
   {
    "duration": 49,
    "start_time": "2023-06-11T08:37:41.453Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-11T08:38:34.867Z"
   },
   {
    "duration": 41,
    "start_time": "2023-06-11T08:42:50.189Z"
   },
   {
    "duration": 791170,
    "start_time": "2023-06-11T08:43:11.450Z"
   },
   {
    "duration": 42,
    "start_time": "2023-06-11T08:57:50.615Z"
   },
   {
    "duration": 795,
    "start_time": "2023-06-11T08:58:12.612Z"
   },
   {
    "duration": 1832,
    "start_time": "2023-06-11T15:05:29.628Z"
   },
   {
    "duration": 835,
    "start_time": "2023-06-11T15:05:31.462Z"
   },
   {
    "duration": 2647,
    "start_time": "2023-06-11T15:05:32.631Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-11T15:05:35.280Z"
   },
   {
    "duration": 78,
    "start_time": "2023-06-11T15:05:35.304Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-11T15:05:35.385Z"
   },
   {
    "duration": 49,
    "start_time": "2023-06-11T15:05:35.417Z"
   },
   {
    "duration": 293,
    "start_time": "2023-06-11T15:05:35.493Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T15:05:39.530Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T15:05:49.406Z"
   },
   {
    "duration": 18134,
    "start_time": "2023-06-11T15:06:10.336Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-11T15:06:28.472Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T15:08:02.551Z"
   },
   {
    "duration": 139,
    "start_time": "2023-06-11T15:08:20.565Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T15:09:02.572Z"
   },
   {
    "duration": 20435,
    "start_time": "2023-06-11T15:09:07.042Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-11T15:12:15.243Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-11T15:12:28.804Z"
   },
   {
    "duration": 399,
    "start_time": "2023-06-11T15:12:45.847Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T15:14:11.260Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T15:14:11.608Z"
   },
   {
    "duration": 932,
    "start_time": "2023-06-11T15:14:11.997Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-11T15:14:12.931Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-11T15:14:12.944Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-11T15:14:13.174Z"
   },
   {
    "duration": 20,
    "start_time": "2023-06-11T15:14:13.353Z"
   },
   {
    "duration": 245,
    "start_time": "2023-06-11T15:14:14.005Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T15:14:14.252Z"
   },
   {
    "duration": 21781,
    "start_time": "2023-06-11T15:15:44.165Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T15:16:11.289Z"
   },
   {
    "duration": 17788,
    "start_time": "2023-06-11T15:16:26.704Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T15:16:44.494Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T15:16:45.546Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T15:16:45.782Z"
   },
   {
    "duration": 909,
    "start_time": "2023-06-11T15:16:45.962Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-11T15:16:46.873Z"
   },
   {
    "duration": 44,
    "start_time": "2023-06-11T15:16:46.886Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-11T15:16:46.991Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-11T15:16:47.488Z"
   },
   {
    "duration": 249,
    "start_time": "2023-06-11T15:16:47.706Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T15:16:48.266Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-11T15:16:49.235Z"
   },
   {
    "duration": 18982,
    "start_time": "2023-06-11T15:17:05.376Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T15:17:45.057Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T15:17:53.254Z"
   },
   {
    "duration": 1550,
    "start_time": "2023-06-11T15:17:59.089Z"
   },
   {
    "duration": 19193,
    "start_time": "2023-06-11T15:18:07.575Z"
   },
   {
    "duration": 451,
    "start_time": "2023-06-11T15:19:28.313Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T15:19:40.765Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T15:19:51.674Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T15:19:52.716Z"
   },
   {
    "duration": 1592,
    "start_time": "2023-06-11T15:19:55.848Z"
   },
   {
    "duration": 808,
    "start_time": "2023-06-11T15:20:03.435Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T15:20:42.462Z"
   },
   {
    "duration": 722591,
    "start_time": "2023-06-11T15:20:46.243Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T15:34:56.868Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-11T15:34:57.343Z"
   },
   {
    "duration": 1005,
    "start_time": "2023-06-11T15:34:57.957Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-11T15:34:58.964Z"
   },
   {
    "duration": 31,
    "start_time": "2023-06-11T15:35:00.035Z"
   },
   {
    "duration": 20,
    "start_time": "2023-06-11T15:35:04.834Z"
   },
   {
    "duration": 47,
    "start_time": "2023-06-11T15:35:05.195Z"
   },
   {
    "duration": 253,
    "start_time": "2023-06-11T15:35:05.946Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T15:35:06.398Z"
   },
   {
    "duration": 23383,
    "start_time": "2023-06-11T15:36:46.589Z"
   },
   {
    "duration": 42,
    "start_time": "2023-06-11T15:37:09.974Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T16:31:37.103Z"
   },
   {
    "duration": 268,
    "start_time": "2023-06-11T16:31:37.736Z"
   },
   {
    "duration": 875,
    "start_time": "2023-06-11T16:31:40.571Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-11T16:31:41.451Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-11T16:31:41.462Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-11T16:31:41.494Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-11T16:31:41.549Z"
   },
   {
    "duration": 227,
    "start_time": "2023-06-11T16:31:41.749Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T16:31:43.597Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-11T16:31:54.476Z"
   },
   {
    "duration": 737488,
    "start_time": "2023-06-11T16:33:49.514Z"
   },
   {
    "duration": 1538,
    "start_time": "2023-06-11T17:23:41.794Z"
   },
   {
    "duration": 192,
    "start_time": "2023-06-11T17:23:43.333Z"
   },
   {
    "duration": 937,
    "start_time": "2023-06-11T17:23:43.527Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-11T17:23:44.466Z"
   },
   {
    "duration": 40,
    "start_time": "2023-06-11T17:23:44.484Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-11T17:23:44.525Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-11T17:23:44.540Z"
   },
   {
    "duration": 238,
    "start_time": "2023-06-11T17:23:44.564Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-11T17:23:44.804Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T17:23:44.818Z"
   },
   {
    "duration": 664561,
    "start_time": "2023-06-11T17:23:44.826Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-11T17:34:49.389Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-11T17:37:54.736Z"
   },
   {
    "duration": 695432,
    "start_time": "2023-06-11T17:37:59.009Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-11T17:50:04.443Z"
   },
   {
    "duration": 57,
    "start_time": "2023-06-11T17:50:51.941Z"
   },
   {
    "duration": 13885,
    "start_time": "2023-06-11T17:52:32.652Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-11T17:58:18.932Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-11T17:58:19.103Z"
   },
   {
    "duration": 874,
    "start_time": "2023-06-11T17:58:19.272Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-11T17:58:20.148Z"
   },
   {
    "duration": 41,
    "start_time": "2023-06-11T17:58:20.163Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-11T17:58:20.206Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-11T17:58:20.229Z"
   },
   {
    "duration": 248,
    "start_time": "2023-06-11T17:58:20.252Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T17:58:23.766Z"
   },
   {
    "duration": 4500357,
    "start_time": "2023-06-11T17:58:31.493Z"
   },
   {
    "duration": 2620,
    "start_time": "2023-06-11T19:19:31.456Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-11T19:20:35.656Z"
   },
   {
    "duration": 931349,
    "start_time": "2023-06-11T19:20:40.179Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-11T19:49:04.578Z"
   },
   {
    "duration": 350,
    "start_time": "2023-06-11T19:49:04.766Z"
   },
   {
    "duration": 1101,
    "start_time": "2023-06-11T19:49:06.706Z"
   },
   {
    "duration": 5430,
    "start_time": "2023-06-11T19:49:13.846Z"
   },
   {
    "duration": 1697,
    "start_time": "2023-06-11T20:47:19.948Z"
   },
   {
    "duration": 759781,
    "start_time": "2023-06-11T20:50:28.571Z"
   },
   {
    "duration": 1737,
    "start_time": "2023-06-12T05:49:58.447Z"
   },
   {
    "duration": 1298,
    "start_time": "2023-06-12T05:50:00.186Z"
   },
   {
    "duration": 2425,
    "start_time": "2023-06-12T05:50:01.485Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-12T05:50:03.913Z"
   },
   {
    "duration": 39,
    "start_time": "2023-06-12T05:50:03.928Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-12T05:50:03.968Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-12T05:50:03.985Z"
   },
   {
    "duration": 227,
    "start_time": "2023-06-12T05:50:04.014Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T05:50:04.246Z"
   },
   {
    "duration": 180,
    "start_time": "2023-06-12T05:50:31.955Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-12T05:50:47.415Z"
   },
   {
    "duration": 1369,
    "start_time": "2023-06-12T05:50:48.959Z"
   },
   {
    "duration": 1342,
    "start_time": "2023-06-12T05:52:31.192Z"
   },
   {
    "duration": 1433,
    "start_time": "2023-06-12T05:55:15.473Z"
   },
   {
    "duration": 20628,
    "start_time": "2023-06-12T05:57:42.636Z"
   },
   {
    "duration": 20,
    "start_time": "2023-06-12T05:58:23.935Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T05:59:06.504Z"
   },
   {
    "duration": 1182,
    "start_time": "2023-06-12T05:59:10.954Z"
   },
   {
    "duration": 68368,
    "start_time": "2023-06-12T05:59:19.116Z"
   },
   {
    "duration": 68752,
    "start_time": "2023-06-12T06:02:50.622Z"
   },
   {
    "duration": 100,
    "start_time": "2023-06-12T06:06:15.385Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-12T06:47:41.142Z"
   },
   {
    "duration": 64,
    "start_time": "2023-06-12T06:47:41.374Z"
   },
   {
    "duration": 1528,
    "start_time": "2023-06-12T06:47:41.699Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-12T06:47:43.229Z"
   },
   {
    "duration": 88,
    "start_time": "2023-06-12T06:47:43.296Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-12T06:47:43.981Z"
   },
   {
    "duration": 26,
    "start_time": "2023-06-12T06:47:44.410Z"
   },
   {
    "duration": 262,
    "start_time": "2023-06-12T06:47:44.733Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T06:47:44.997Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-12T06:47:45.417Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T07:02:40.519Z"
   },
   {
    "duration": 1046,
    "start_time": "2023-06-12T07:02:40.874Z"
   },
   {
    "duration": 1272,
    "start_time": "2023-06-12T07:02:41.922Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-12T07:02:43.208Z"
   },
   {
    "duration": 63,
    "start_time": "2023-06-12T07:02:43.227Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-12T07:02:43.292Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-12T07:02:46.412Z"
   },
   {
    "duration": 283,
    "start_time": "2023-06-12T07:02:46.824Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-12T07:02:47.827Z"
   },
   {
    "duration": 2,
    "start_time": "2023-06-12T07:02:50.712Z"
   },
   {
    "duration": 27423,
    "start_time": "2023-06-12T07:03:02.412Z"
   },
   {
    "duration": 22919,
    "start_time": "2023-06-12T07:05:02.111Z"
   },
   {
    "duration": 127,
    "start_time": "2023-06-12T07:23:51.939Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T07:46:36.552Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T08:28:33.592Z"
   },
   {
    "duration": 633,
    "start_time": "2023-06-12T08:28:37.241Z"
   },
   {
    "duration": 2342,
    "start_time": "2023-06-12T08:28:38.437Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-12T08:28:40.781Z"
   },
   {
    "duration": 45,
    "start_time": "2023-06-12T08:28:40.798Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-12T08:28:40.846Z"
   },
   {
    "duration": 54,
    "start_time": "2023-06-12T08:28:40.865Z"
   },
   {
    "duration": 233,
    "start_time": "2023-06-12T08:28:40.920Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T08:28:41.154Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-12T08:28:41.162Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T08:28:42.052Z"
   },
   {
    "duration": 128,
    "start_time": "2023-06-12T08:28:56.700Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T09:25:53.514Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-12T09:25:53.965Z"
   },
   {
    "duration": 987,
    "start_time": "2023-06-12T09:25:54.384Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-12T09:25:55.375Z"
   },
   {
    "duration": 1870311,
    "start_time": "2023-06-12T09:26:05.639Z"
   },
   {
    "duration": 4056,
    "start_time": "2023-06-12T10:55:09.975Z"
   },
   {
    "duration": 143,
    "start_time": "2023-06-12T10:55:14.033Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.178Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.179Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.180Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.181Z"
   },
   {
    "duration": 1,
    "start_time": "2023-06-12T10:55:14.182Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.184Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.185Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.186Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.187Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.188Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.189Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T10:55:14.190Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-12T10:57:23.310Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-12T10:57:24.127Z"
   },
   {
    "duration": 148,
    "start_time": "2023-06-12T10:57:39.510Z"
   },
   {
    "duration": 88,
    "start_time": "2023-06-12T10:57:43.474Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-12T10:57:48.268Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T10:57:58.461Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-12T10:58:02.172Z"
   },
   {
    "duration": 55,
    "start_time": "2023-06-12T10:58:18.483Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-12T10:58:20.039Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T10:58:48.722Z"
   },
   {
    "duration": 754,
    "start_time": "2023-06-12T10:58:49.863Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T10:59:41.141Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-12T10:59:42.715Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T10:59:58.843Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-12T11:01:03.567Z"
   },
   {
    "duration": 2703,
    "start_time": "2023-06-12T11:01:04.668Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-12T11:01:10.752Z"
   },
   {
    "duration": 37,
    "start_time": "2023-06-12T11:01:11.640Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-12T11:01:12.104Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-12T11:01:12.506Z"
   },
   {
    "duration": 259,
    "start_time": "2023-06-12T11:01:12.760Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T11:01:13.365Z"
   },
   {
    "duration": 38,
    "start_time": "2023-06-12T11:01:15.409Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-12T11:01:25.864Z"
   },
   {
    "duration": 30,
    "start_time": "2023-06-12T11:01:41.641Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T11:03:03.755Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-12T11:03:10.745Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T11:03:34.097Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-12T11:03:35.039Z"
   },
   {
    "duration": 954,
    "start_time": "2023-06-12T11:03:35.683Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-12T11:03:36.639Z"
   },
   {
    "duration": 56,
    "start_time": "2023-06-12T11:03:36.662Z"
   },
   {
    "duration": 55,
    "start_time": "2023-06-12T11:03:36.720Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-12T11:03:37.061Z"
   },
   {
    "duration": 244,
    "start_time": "2023-06-12T11:03:37.298Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T11:03:37.698Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T11:03:38.688Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-12T11:03:39.673Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-12T11:04:14.220Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-12T11:04:36.716Z"
   },
   {
    "duration": 16,
    "start_time": "2023-06-12T11:05:06.184Z"
   },
   {
    "duration": 31,
    "start_time": "2023-06-12T11:05:53.110Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-12T11:06:59.170Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-12T11:08:29.117Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T11:08:30.550Z"
   },
   {
    "duration": 1637,
    "start_time": "2023-06-12T11:23:26.203Z"
   },
   {
    "duration": 239,
    "start_time": "2023-06-12T11:23:27.842Z"
   },
   {
    "duration": 963,
    "start_time": "2023-06-12T11:23:28.083Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-12T11:23:29.048Z"
   },
   {
    "duration": 33,
    "start_time": "2023-06-12T11:23:29.065Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-12T11:23:29.100Z"
   },
   {
    "duration": 51,
    "start_time": "2023-06-12T11:23:29.116Z"
   },
   {
    "duration": 234,
    "start_time": "2023-06-12T11:23:29.169Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T11:23:29.405Z"
   },
   {
    "duration": 92,
    "start_time": "2023-06-12T11:23:29.413Z"
   },
   {
    "duration": 769884,
    "start_time": "2023-06-12T11:23:29.507Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T11:36:19.392Z"
   },
   {
    "duration": 194,
    "start_time": "2023-06-12T11:36:19.398Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T11:36:19.594Z"
   },
   {
    "duration": 3507,
    "start_time": "2023-06-12T15:09:13.544Z"
   },
   {
    "duration": 765,
    "start_time": "2023-06-12T15:09:17.053Z"
   },
   {
    "duration": 3363,
    "start_time": "2023-06-12T15:09:17.820Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-12T15:09:21.187Z"
   },
   {
    "duration": 54,
    "start_time": "2023-06-12T15:09:21.207Z"
   },
   {
    "duration": 67,
    "start_time": "2023-06-12T15:09:21.263Z"
   },
   {
    "duration": 40,
    "start_time": "2023-06-12T15:09:21.332Z"
   },
   {
    "duration": 303,
    "start_time": "2023-06-12T15:09:21.374Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T15:09:21.679Z"
   },
   {
    "duration": 134,
    "start_time": "2023-06-12T15:09:21.690Z"
   },
   {
    "duration": 1865,
    "start_time": "2023-06-12T15:29:36.792Z"
   },
   {
    "duration": 321,
    "start_time": "2023-06-12T15:29:38.659Z"
   },
   {
    "duration": 1056,
    "start_time": "2023-06-12T15:29:38.982Z"
   },
   {
    "duration": 37,
    "start_time": "2023-06-12T15:29:40.041Z"
   },
   {
    "duration": 55,
    "start_time": "2023-06-12T15:29:40.080Z"
   },
   {
    "duration": 39,
    "start_time": "2023-06-12T15:29:40.136Z"
   },
   {
    "duration": 31,
    "start_time": "2023-06-12T15:29:40.177Z"
   },
   {
    "duration": 275,
    "start_time": "2023-06-12T15:29:40.210Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-12T15:29:40.487Z"
   },
   {
    "duration": 80,
    "start_time": "2023-06-12T15:29:40.497Z"
   },
   {
    "duration": 916040,
    "start_time": "2023-06-12T15:29:40.579Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-12T15:44:56.621Z"
   },
   {
    "duration": 20610,
    "start_time": "2023-06-12T15:44:56.628Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T15:45:17.240Z"
   },
   {
    "duration": 1883,
    "start_time": "2023-06-12T16:50:31.825Z"
   },
   {
    "duration": 262,
    "start_time": "2023-06-12T16:50:33.710Z"
   },
   {
    "duration": 1140,
    "start_time": "2023-06-12T16:50:33.974Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-12T16:50:35.116Z"
   },
   {
    "duration": 55,
    "start_time": "2023-06-12T16:50:35.145Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-12T16:50:35.202Z"
   },
   {
    "duration": 34,
    "start_time": "2023-06-12T16:50:35.232Z"
   },
   {
    "duration": 306,
    "start_time": "2023-06-12T16:50:35.268Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T16:50:35.576Z"
   },
   {
    "duration": 99,
    "start_time": "2023-06-12T16:50:35.583Z"
   },
   {
    "duration": 928193,
    "start_time": "2023-06-12T16:50:35.684Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T17:06:03.879Z"
   },
   {
    "duration": 2347,
    "start_time": "2023-06-12T18:08:10.015Z"
   },
   {
    "duration": 1032,
    "start_time": "2023-06-12T18:08:12.364Z"
   },
   {
    "duration": 3512,
    "start_time": "2023-06-12T18:08:13.398Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-12T18:08:16.912Z"
   },
   {
    "duration": 31,
    "start_time": "2023-06-12T18:08:16.929Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-12T18:08:16.961Z"
   },
   {
    "duration": 28,
    "start_time": "2023-06-12T18:08:16.989Z"
   },
   {
    "duration": 243,
    "start_time": "2023-06-12T18:08:17.019Z"
   },
   {
    "duration": 24,
    "start_time": "2023-06-12T18:08:17.264Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-12T18:08:17.289Z"
   },
   {
    "duration": 747489,
    "start_time": "2023-06-12T18:08:17.301Z"
   },
   {
    "duration": 3,
    "start_time": "2023-06-12T18:20:44.792Z"
   },
   {
    "duration": 5261161,
    "start_time": "2023-06-12T18:20:44.797Z"
   },
   {
    "duration": 25,
    "start_time": "2023-06-12T19:48:25.961Z"
   },
   {
    "duration": 129783,
    "start_time": "2023-06-12T20:02:07.493Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T20:04:17.278Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-12T20:04:17.279Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-12T20:04:24.767Z"
   },
   {
    "duration": 158,
    "start_time": "2023-06-12T20:04:34.777Z"
   },
   {
    "duration": 14,
    "start_time": "2023-06-12T20:05:20.306Z"
   },
   {
    "duration": 23,
    "start_time": "2023-06-12T20:06:24.801Z"
   },
   {
    "duration": 133,
    "start_time": "2023-06-12T20:07:03.252Z"
   },
   {
    "duration": 132,
    "start_time": "2023-06-12T20:07:19.903Z"
   },
   {
    "duration": 3978,
    "start_time": "2023-06-12T20:07:49.159Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-12T20:08:30.999Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-12T20:12:08.058Z"
   },
   {
    "duration": 275,
    "start_time": "2023-06-12T20:12:08.922Z"
   },
   {
    "duration": 920,
    "start_time": "2023-06-12T20:12:09.671Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-12T20:12:10.593Z"
   },
   {
    "duration": 37,
    "start_time": "2023-06-12T20:12:10.607Z"
   },
   {
    "duration": 35,
    "start_time": "2023-06-12T20:12:10.645Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-12T20:12:10.719Z"
   },
   {
    "duration": 229,
    "start_time": "2023-06-12T20:12:11.491Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-12T20:12:12.371Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-12T20:12:20.654Z"
   },
   {
    "duration": 95,
    "start_time": "2023-06-14T07:17:14.706Z"
   },
   {
    "duration": 133,
    "start_time": "2023-06-14T07:18:13.964Z"
   },
   {
    "duration": 1637,
    "start_time": "2023-06-14T07:23:26.357Z"
   },
   {
    "duration": 808,
    "start_time": "2023-06-14T07:23:27.998Z"
   },
   {
    "duration": 1624,
    "start_time": "2023-06-14T07:23:28.809Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-14T07:23:30.435Z"
   },
   {
    "duration": 57,
    "start_time": "2023-06-14T07:23:30.453Z"
   },
   {
    "duration": 59,
    "start_time": "2023-06-14T07:23:30.514Z"
   },
   {
    "duration": 44,
    "start_time": "2023-06-14T07:23:30.575Z"
   },
   {
    "duration": 277,
    "start_time": "2023-06-14T07:23:30.780Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-14T07:23:31.665Z"
   },
   {
    "duration": 10,
    "start_time": "2023-06-14T07:23:33.987Z"
   },
   {
    "duration": 915998,
    "start_time": "2023-06-14T07:23:42.686Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T07:41:53.081Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-14T07:46:04.088Z"
   },
   {
    "duration": 2549,
    "start_time": "2023-06-14T12:50:46.710Z"
   },
   {
    "duration": 748,
    "start_time": "2023-06-14T12:50:49.263Z"
   },
   {
    "duration": 1481,
    "start_time": "2023-06-14T12:50:50.013Z"
   },
   {
    "duration": 15,
    "start_time": "2023-06-14T12:50:51.496Z"
   },
   {
    "duration": 53,
    "start_time": "2023-06-14T12:50:51.514Z"
   },
   {
    "duration": 50,
    "start_time": "2023-06-14T12:50:51.570Z"
   },
   {
    "duration": 75,
    "start_time": "2023-06-14T12:50:51.621Z"
   },
   {
    "duration": 282,
    "start_time": "2023-06-14T12:50:51.697Z"
   },
   {
    "duration": 7,
    "start_time": "2023-06-14T12:50:51.980Z"
   },
   {
    "duration": 34,
    "start_time": "2023-06-14T12:50:51.988Z"
   },
   {
    "duration": 10989,
    "start_time": "2023-06-14T12:50:52.024Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-14T12:51:03.015Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-14T12:51:03.016Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-14T12:51:03.018Z"
   },
   {
    "duration": 0,
    "start_time": "2023-06-14T12:51:03.019Z"
   },
   {
    "duration": 4,
    "start_time": "2023-06-14T12:52:30.494Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-14T12:52:35.992Z"
   },
   {
    "duration": 1014,
    "start_time": "2023-06-14T12:52:37.225Z"
   },
   {
    "duration": 27,
    "start_time": "2023-06-14T12:52:38.249Z"
   },
   {
    "duration": 48,
    "start_time": "2023-06-14T12:52:38.617Z"
   },
   {
    "duration": 20,
    "start_time": "2023-06-14T12:52:39.190Z"
   },
   {
    "duration": 31,
    "start_time": "2023-06-14T12:52:39.763Z"
   },
   {
    "duration": 245,
    "start_time": "2023-06-14T12:52:40.386Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-14T12:52:40.761Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-14T12:52:43.212Z"
   },
   {
    "duration": 849768,
    "start_time": "2023-06-14T12:52:59.406Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-14T13:07:12.780Z"
   },
   {
    "duration": 1717,
    "start_time": "2023-06-14T14:29:30.924Z"
   },
   {
    "duration": 326,
    "start_time": "2023-06-14T14:29:32.644Z"
   },
   {
    "duration": 1104,
    "start_time": "2023-06-14T14:29:32.973Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-14T14:29:34.079Z"
   },
   {
    "duration": 85,
    "start_time": "2023-06-14T14:29:34.100Z"
   },
   {
    "duration": 44,
    "start_time": "2023-06-14T14:29:34.187Z"
   },
   {
    "duration": 91,
    "start_time": "2023-06-14T14:29:34.233Z"
   },
   {
    "duration": 350,
    "start_time": "2023-06-14T14:29:34.326Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-14T14:29:34.678Z"
   },
   {
    "duration": 36,
    "start_time": "2023-06-14T14:29:34.686Z"
   },
   {
    "duration": 931237,
    "start_time": "2023-06-14T14:29:34.724Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-14T14:45:05.963Z"
   },
   {
    "duration": 5909226,
    "start_time": "2023-06-14T14:45:05.972Z"
   },
   {
    "duration": 8,
    "start_time": "2023-06-14T16:23:35.203Z"
   },
   {
    "duration": 50,
    "start_time": "2023-06-14T16:23:35.213Z"
   },
   {
    "duration": 141,
    "start_time": "2023-06-14T16:34:38.270Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-14T16:36:02.143Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-14T16:36:34.114Z"
   },
   {
    "duration": 11,
    "start_time": "2023-06-14T16:36:42.221Z"
   },
   {
    "duration": 19664,
    "start_time": "2023-06-14T16:39:43.916Z"
   },
   {
    "duration": 19170,
    "start_time": "2023-06-14T16:46:55.010Z"
   },
   {
    "duration": 7832,
    "start_time": "2023-06-14T16:59:27.376Z"
   },
   {
    "duration": 1563,
    "start_time": "2023-06-15T10:13:23.586Z"
   },
   {
    "duration": 697,
    "start_time": "2023-06-15T10:13:25.151Z"
   },
   {
    "duration": 3920,
    "start_time": "2023-06-15T10:13:25.850Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-15T10:13:29.774Z"
   },
   {
    "duration": 53,
    "start_time": "2023-06-15T10:13:29.798Z"
   },
   {
    "duration": 22,
    "start_time": "2023-06-15T10:13:29.853Z"
   },
   {
    "duration": 45,
    "start_time": "2023-06-15T10:13:29.879Z"
   },
   {
    "duration": 267,
    "start_time": "2023-06-15T10:13:29.926Z"
   },
   {
    "duration": 9,
    "start_time": "2023-06-15T10:13:30.195Z"
   },
   {
    "duration": 24,
    "start_time": "2023-06-15T10:13:30.216Z"
   },
   {
    "duration": 793802,
    "start_time": "2023-06-15T10:13:30.242Z"
   },
   {
    "duration": 5,
    "start_time": "2023-06-15T10:26:44.046Z"
   },
   {
    "duration": 5493794,
    "start_time": "2023-06-15T10:26:44.054Z"
   },
   {
    "duration": 6,
    "start_time": "2023-06-15T11:58:17.850Z"
   },
   {
    "duration": 38,
    "start_time": "2023-06-15T11:58:17.858Z"
   },
   {
    "duration": 1251,
    "start_time": "2023-06-15T11:58:17.897Z"
   },
   {
    "duration": 18,
    "start_time": "2023-06-15T12:22:13.673Z"
   },
   {
    "duration": 17,
    "start_time": "2023-06-15T12:24:57.002Z"
   },
   {
    "duration": 13,
    "start_time": "2023-06-15T12:25:22.735Z"
   },
   {
    "duration": 21,
    "start_time": "2023-06-15T12:25:45.634Z"
   },
   {
    "duration": 12,
    "start_time": "2023-06-15T12:26:01.830Z"
   },
   {
    "duration": 18954,
    "start_time": "2023-06-15T12:28:31.406Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
